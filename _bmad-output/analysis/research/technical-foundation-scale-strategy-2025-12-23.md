---
stepsCompleted: [1, 2, 3]
inputDocuments: []
workflowType: 'research'
lastStep: 3
research_type: 'technical'
research_topic: 'Foundation-And-Scale-Strategy'
research_goals: 'Implement GPU Bloom Filters, Multi-Path Derivation, and Automated Cross-Validation for the All-In success strategy.'
user_name: 'Moe'
date: '2025-12-23'
web_research_enabled: true
source_verification: true
---

# Technical Research: Foundation & Scale Strategy for Temporal Planetarium

**Date:** 2025-12-23
**Researcher:** Antigravity (AI Assistant)
**Stakeholder:** Moe (Project Lead)

---

## Executive Summary

This research document provides the technical foundation for the "All-In" success strategy identified during the Phase 10 retrospective for Temporal Planetarium. It covers three critical topics necessary to achieve a step-change in the project's scanning capabilities:

1.  **GPU Bloom Filters**: For scaling target address lookups from 1 to 1,000,000+.
2.  **Multi-Path Derivation Optimization**: For covering BIP44/49/84/86 and address indices 0-100+.
3.  **Automated Cross-Validation**: For ensuring 100% parity with external research tools like CryptoDeepTools.

---

## Table of Contents

- [1. GPU Bloom Filter Implementation](#1-gpu-bloom-filter-implementation)
  - [1.1 Core Concepts](#11-core-concepts)
  - [1.2 GPU-Specific Variants](#12-gpu-specific-variants)
  - [1.3 OpenCL Implementation Strategy](#13-opencl-implementation-strategy)
  - [1.4 Implementation Recommendations](#14-implementation-recommendations)
- [2. Multi-Path Derivation Optimization](#2-multi-path-derivation-optimization)
  - [2.1 BIP Standards Overview](#21-bip-standards-overview)
  - [2.2 GPU Acceleration for Derivation](#22-gpu-acceleration-for-derivation)
  - [2.3 Implementation Recommendations](#23-implementation-recommendations)
- [3. Automated Cross-Validation Parity](#3-automated-cross-validation-parity)
  - [3.1 The Role of Cross-Validation](#31-the-role-of-cross-validation)
  - [3.2 Parity Testing Methodology](#32-parity-testing-methodology)
  - [3.3 Implementation Recommendations](#33-implementation-recommendations)
- [4. Conclusions and Next Steps](#4-conclusions-and-next-steps)

---

## 1. GPU Bloom Filter Implementation

### 1.1 Core Concepts

A Bloom filter is a space-efficient probabilistic data structure used to test whether an element is a member of a set. It may yield false positives (claiming an element is present when it isn't) but never false negatives (it will always correctly identify if an element is NOT present).

**The Key Formula (False Positive Rate):**

The probability `p` of a false positive is:

> **p â‰ˆ (1 - e^(-kn/m))^k** [[Source: Wikipedia]](https://en.wikipedia.org/wiki/Bloom_filter)

Where:
-   `m` = size of the bit array.
-   `n` = number of items inserted.
-   `k` = number of hash functions.

**Optimal Number of Hash Functions:**

> **k_optimal = (m/n) * ln(2)** [[Source: uth.gr]](https://www.e-ce.uth.gr/wp-content/uploads/formidable/24/thesis_2016_TI_NIKOLOPOULOS.pdf)

This minimizes the false positive rate for a given `m/n` ratio.

**Confidence Level:** [High Confidence] - These formulas are well-established in computer science literature.

### 1.2 GPU-Specific Variants

Research shows that standard Bloom filters can be adapted for GPU architectures to achieve massive parallelism:

-   **Blocked Bloom Filters (BBF)**: Partition the bit array into cache-sized blocks. This improves memory access locality. [[Source: arxiv.org]](https://arxiv.org/abs/2103.16989)
-   **Register Blocked Bloom Filters (RBBF)**: Set the block size to the machine word size (e.g., 32 or 64 bits) to minimize computational overhead.
-   **Cache-Sectorized Bloom Filters (CSBF)**: Subdivide blocks into "sectors" aligned to GPU cache lines (e.g., 256-bit) to maximize memory bandwidth utilization.

**Performance Characteristics:**

Recent optimized GPU Bloom filter designs have achieved over **92% of the theoretical "speed-of-light"** for random-access bandwidth on NVIDIA B200 GPUs, outperforming naive state-of-the-art by up to **15.4x for bulk lookups** and **11.35x for filter construction**. [[Source: themoonlight.io]](https://themoonlight.io/p/gpu-bloom-filters-are-fast-bloat)

**Confidence Level:** [High Confidence] - Based on peer-reviewed research and industry benchmarks.

### 1.3 OpenCL Implementation Strategy

While the most advanced research is often in CUDA, OpenCL can achieve comparable performance (often within **90%** of CUDA speeds) for well-optimized kernels. [[Source: Reddit]](https://www.reddit.com/r/CUDA/comments/12l53uo/cuda_vs_opencl_which_do_you_prefer/)

**Key Optimization Dimensions for OpenCL:**

1.  **Vectorization**: Use vector types (`ulong4`, `uint8`) to process multiple bits per thread.
2.  **Thread Cooperation**: Use work-groups where threads cooperatively compute hash values.
3.  **Compute Latency**: Use branchless multiplicative hashing. Inline hash salts into the kernel to avoid memory loads.
4.  **Memory Layout**: Use a fully horizontal layout for insertions (coalesced writes). Use a purely vertical layout for lookups if `k` is large.

**Confidence Level:** [Medium Confidence] - OpenCL parity with CUDA depends heavily on kernel optimization and vendor drivers.

### 1.4 Implementation Recommendations

| Recommendation | Rationale |
|----------------|-----------|
| **Use Blocked Bloom Filters aligned to GPU cache lines (256-bit).** | Maximizes L1 cache hits and memory bandwidth. |
| **Calculate `k_optimal` based on target FPR.** | For 1M addresses and 0.1% FPR, target ~15 hash functions. |
| **Implement as a single, flat `__global uchar*` buffer.** | Simplifies host-device transfer for OpenCL. |
| **Pre-compute all target address hashes on the host.** | Populate the filter once; query millions of times on the GPU. |
| **Benchmark against linear search first.** | Establish baseline before optimizing. |

---

## 2. Multi-Path Derivation Optimization

### 2.1 BIP Standards Overview

Hierarchical Deterministic (HD) wallets derive all keys from a single seed phrase. Several BIPs standardize derivation paths for different address formats:

| BIP | Purpose Constant | Address Format | Address Prefix | Extended Key Prefix |
|-----|------------------|----------------|----------------|---------------------|
| **BIP-44** | `44'` | P2PKH (Legacy) | `1...` | `xpub`/`xprv` |
| **BIP-49** | `49'` | P2SH-P2WPKH (SegWit-compat) | `3...` | `ypub`/`yprv` |
| **BIP-84** | `84'` | P2WPKH (Native SegWit) | `bc1q...` | `zpub`/`zprv` |
| **BIP-86** | `86'` | P2TR (Taproot) | `bc1p...` | `xpub`/`xprv` (no unique prefix) |

[[Source: learnmeabitcoin.com]](https://learnmeabitcoin.com/technical/derivation-paths/)

**Extended Indices:**

Standard wallets typically check address index `0` first. However, a user who has received multiple transactions may have funds on indices `1` through `100+`. Covering this range is essential for complete vulnerability analysis.

**Confidence Level:** [High Confidence] - BIP standards are canonical references.

### 2.2 GPU Acceleration for Derivation

The core cryptographic operations in key derivation are:
1.  **HMAC-SHA512**: For BIP-32 child key generation.
2.  **Secp256k1 Scalar Multiplication**: For deriving public keys from private keys.
3.  **Hash160 (SHA256 + RIPEMD160)**: For generating Bitcoin addresses.

GPUs excel at parallelizing these operations. Tools like **BTCRecover** demonstrate that GPUs can achieve **4x to 96x** speedups over CPUs for BIP-39 related hashing tasks, such as passphrase recovery. [[Source: BTCRecover Docs]](https://btcrecover.readthedocs.io/en/latest/GPU_Acceleration/)

**Batching Strategy:**

To efficiently cover 4 derivation paths (BIP44/49/84/86) and 100 indices simultaneously, we need to batch these operations:

-   **Total Keys per Seed**: `4 paths * 100 indices = 400 keys/addresses`.
-   **GPU Work Items**: Each GPU thread handles one `(path, index)` tuple.
-   **Kernel Design**: The kernel takes a single derived `chain_key` (for account `0'`) and iterates to produce `400` addresses in parallel.

**Confidence Level:** [High Confidence] - Batching is the standard approach for GPU-accelerated HD wallet scanning.

### 2.3 Implementation Recommendations

| Recommendation | Rationale |
|----------------|-----------|
| **Implement a "Derivation Batcher" module.** | Takes a seed, outputs 400+ addresses in a single kernel call. |
| **Perform HMAC-SHA512 on GPU.** | The most compute-intensive step; parallelize across all tuples. |
| **Use a lookup table for address type encoding.** | Avoid branching in the kernel for P2PKH/P2WPKH/P2SH/P2TR differences. |
| **Cache the "Account Master Key" on the host.** | Derive once per seed, then let the GPU derive child keys. |
| **Test against `bitcoin-rust` reference implementation.** | Ensure bit-perfect parity before scaling. |

---

## 3. Automated Cross-Validation Parity

### 3.1 The Role of Cross-Validation

Cross-validation in this context ensures that Temporal Planetarium's output is **identical** to that of reference implementations (like CryptoDeepTools or `bitcoin-rust`) for the same inputs. This is "parity testing" rather than ML-style k-fold cross-validation.

**Why It Matters:**

A single bit-flip in a hash or a mishandled endianness can cause a scan to miss a vulnerable wallet. Automated parity testing catches these subtle bugs before they become costly false negatives.

**Confidence Level:** [High Confidence] - Parity testing is a standard practice in cryptographic software development.

### 3.2 Parity Testing Methodology

Based on security audit practices (e.g., Trail of Bits' audit of Parity Fether), effective parity testing includes:

1.  **Comprehensive Test Vectors**: A large, diverse set of inputs covering edge cases.
2.  **Property-Based Testing**: Define abstract properties (e.g., "address derivation is deterministic") and fuzz with random inputs.
3.  **Multiple Independent Sources**: Validate against at least two reference implementations.

[[Source: Parity.io Fether Audit]](https://www.parity.io/blog/fether-security-audit)

For Temporal Planetarium, this translates to:

-   **Input**: A JSON file of test vectors with `{seed, path, index, expected_address}`.
-   **Execution**: Run both `temporal-planetarium-lib` and CryptoDeepTools (via Python FFI).
-   **Comparison**: Assert byte-perfect equality on the resulting addresses.

### 3.3 Implementation Recommendations

| Recommendation | Rationale |
|----------------|-----------|
| **Expand `shared_test_vectors.json` to 10,000+ vectors.** | Cover edge cases, all supported engines, and all BIP paths. |
| **Create a `scripts/validate_parity.py` script.** | Runs both Rust and CryptoDeepTools Python, compares outputs. |
| **Integrate into CI/CD pipeline.** | Fail the build if parity diverges. |
| **Use property-based testing (e.g., `proptest` in Rust).** | Generate random seeds/paths and validate determinism. |
| **Track "Parity Score" as a KPI (100% is the target).** | Any deviation is a regression. |

---

## 4. Conclusions and Next Steps

This research confirms the feasibility and outlines the implementation strategy for the three pillars of the "All-In" success strategy.

### Key Takeaways:

-   **GPU Bloom Filters** are well-researched and can provide 10x+ speedups for target set lookups. **Blocked Bloom Filters (BBF)** aligned to GPU cache lines are the recommended architecture for OpenCL.
-   **Multi-Path Derivation** on GPUs is achievable by batching 400+ `(path, index)` tuples per kernel call. The `Derivation Batcher` pattern is the core abstraction needed.
-   **Automated Cross-Validation** requires a significant expansion of `shared_test_vectors.json` and a dedicated Python validation script integrated into CI.

### Recommended Phase 11 Epics:

1.  **EPIC-003: GPU Bloom Filter Integration**
    -   Story: Implement OpenCL BBF kernel.
    -   Story: Benchmark against linear scan.
    -   Story: Integrate with Randstorm scanner.

2.  **EPIC-004: Multi-Path Derivation Batcher**
    -   Story: Implement `DerivationBatcher` module in Rust.
    -   Story: Create GPU kernel for HMAC-SHA512 batching.
    -   Story: Extend CLI to accept `--path-coverage all`.

3.  **EPIC-005: Automated Parity Suite**
    -   Story: Generate 10,000+ test vectors (all engines, all paths).
    -   Story: Create `validate_parity.py` script.
    -   Story: Add parity check to GitHub Actions CI.

---

## Sources

1.  [arxiv.org - GPU Bloom Filters](https://arxiv.org/abs/2103.16989)
2.  [themoonlight.io - GPU Bloom Filters Performance](https://themoonlight.io/p/gpu-bloom-filters-are-fast-bloat)
3.  [Wikipedia - Bloom Filter](https://en.wikipedia.org/wiki/Bloom_filter)
4.  [learnmeabitcoin.com - Derivation Paths](https://learnmeabitcoin.com/technical/derivation-paths/)
5.  [BTCRecover Docs - GPU Acceleration](https://btcrecover.readthedocs.io/en/latest/GPU_Acceleration/)
6.  [Parity.io - Fether Security Audit](https://www.parity.io/blog/fether-security-audit)
7.  [GitHub - Coinspect WSVS](https://github.com/nicoptere/wallet-security-verification-standard)

---

_This document serves as the authoritative research reference for Phase 11 planning._
